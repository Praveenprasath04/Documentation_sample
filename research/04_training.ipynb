{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Documentation_sample\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Documentation_sample'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path : Path\n",
    "    base_model_path: Path\n",
    "    train_loader_dir : Path\n",
    "    valid_loader_dir :  Path\n",
    "    params_batch_size : int\n",
    "    params_valid_size : float\n",
    "    params_learning_rate : float\n",
    "    params_momentum: float\n",
    "    params_image_dim : int\n",
    "    params_random_seed: int\n",
    "    params_epochs: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample_project.constants import *\n",
    "from sample_project.utils.common import read_yaml, create_directories\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        params = self.params\n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            base_model_path=Path(training.base_model_path),\n",
    "            train_loader_dir=Path(training.train_loader_dir),\n",
    "            valid_loader_dir = Path(training.valid_loader_dir),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_learning_rate = params.LEARNING_RATE,\n",
    "            params_momentum = params.MOMENTUM,\n",
    "            params_image_dim = params.IMAGE_DIM,\n",
    "            params_random_seed = params.RANDOM_SEED,\n",
    "            params_valid_size = params.VALID_SIZE\n",
    "        )\n",
    "\n",
    "        return training_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "import zipfile\n",
    "from sample_project import logger\n",
    "from sample_project.utils.common import get_size,accuracy\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def loading_iterators(self):\n",
    "        self.train_iterator = torch.load(self.config.train_loader_dir)\n",
    "        self.valid_iterator = torch.load(self.config.valid_loader_dir)\n",
    "\n",
    "    def initializing_model(self):\n",
    "        base_model = torch.load(self.config.base_model_path)\n",
    "        torch.save(base_model, self.config.trained_model_path)\n",
    "        self.model = torch.load(self.config.trained_model_path)\n",
    "        self.model = self.model.to(self.device)  # Move model to the specified device\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def train(self):\n",
    "        \n",
    "        self.valid_accuracy, self.valid_loss = self.train_loop(self.model, self.train_iterator, self.valid_iterator,\n",
    "                                                               self.config.params_epochs, self.config.params_learning_rate,\n",
    "                                                               self.config.params_momentum, self.loss_fn)\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(self.valid_loss)\n",
    "        plt.title(\"Validation Loss VS Number Of Epochs\")\n",
    "        plt.xlabel(\"Number of Epochs\")\n",
    "        plt.ylabel(\"Validation_Loss\")\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(self.valid_accuracy)\n",
    "        plt.title(\"Validation accuracy VS Number Of Epochs\")\n",
    "        plt.xlabel(\"Number of Epochs\")\n",
    "        plt.ylabel(\"Validation_accuracy\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def train_loop(model, train_iterator, valid_iterator, epochs: int, learning_rate: float, momentum: float, Loss_function):\n",
    "        \n",
    "        device = next(model.parameters()).device  # Get the device from the model\n",
    "\n",
    "        n_iterations_per_epoch = len(train_iterator)\n",
    "        n_iterations_validation = len(valid_iterator)\n",
    "\n",
    "        best_loss_val = np.infty\n",
    "\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "        Valid_loss = []\n",
    "        Valid_accuracy = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "\n",
    "            for iteration, idata in enumerate(train_iterator, 1):\n",
    "                inputs, targets = idata\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                loss = Loss_function(outputs, targets)\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                current_loss = loss.item()\n",
    "\n",
    "                print(\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\".format(\n",
    "                        iteration, n_iterations_per_epoch,\n",
    "                        iteration * 100 / n_iterations_per_epoch,\n",
    "                        current_loss),\n",
    "                    end=\"\")\n",
    "                break\n",
    "\n",
    "            model.eval()\n",
    "            loss_vals = []\n",
    "            acc_vals = []\n",
    "            with torch.no_grad():\n",
    "                for iteration, idata in enumerate(valid_iterator, 1):\n",
    "                    inputs, targets = idata\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    current_loss = Loss_function(outputs, targets)\n",
    "                    current_accuracy = accuracy(outputs, targets)\n",
    "                    loss_vals.append(float(current_loss))\n",
    "                    acc_vals.append(float(current_accuracy))\n",
    "                    print(\"\\rEvaluating the model: {}/{} ({:.1f}%) Loss: {:.5f} accuracy: {:.5f}\".format(\n",
    "                            iteration, n_iterations_validation,\n",
    "                            iteration * 100 / n_iterations_validation, current_loss, current_accuracy),\n",
    "                        end=\" \" * 10)\n",
    "                    break\n",
    "\n",
    "\n",
    "                loss_val = np.mean(loss_vals)\n",
    "                acc_val = np.mean(acc_vals)\n",
    "\n",
    "                Valid_loss.append(loss_val)\n",
    "                Valid_accuracy.append(acc_val)\n",
    "\n",
    "                print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}\".format(\n",
    "                    epoch + 1, acc_val * 100, loss_val,\n",
    "                    \"(improved)\" if loss_val < best_loss_val else \"\"))\n",
    "                if epoch+1==epochs:\n",
    "                    logger.info(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n",
    "                    epoch + 1, acc_val * 100, loss_val))\n",
    "\n",
    "                if loss_val < best_loss_val:\n",
    "                    best_loss_val = loss_val\n",
    "        \n",
    "\n",
    "        return Valid_accuracy, Valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-29 17:47:08,650: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-07-29 17:47:08,652: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-07-29 17:47:08,653: INFO: common: created directory at: artifacts]\n",
      "[2024-07-29 17:47:08,655: INFO: common: created directory at: artifacts\\training]\n",
      "Epoch: 1  Val accuracy: 7.8125%  Loss: 2.304518 accuracy: 0.07812          \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Replacement index 3 out of range for positional args tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     Training_step\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m     Training_step\u001b[38;5;241m.\u001b[39mloading_iterators()\n\u001b[0;32m      6\u001b[0m     Training_step\u001b[38;5;241m.\u001b[39minitializing_model()\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mTraining_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m, in \u001b[0;36mTraining.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_accuracy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams_learning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams_momentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     23\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_loss)\n",
      "Cell \u001b[1;32mIn[8], line 115\u001b[0m, in \u001b[0;36mTraining.train_loop\u001b[1;34m(model, train_iterator, valid_iterator, epochs, learning_rate, momentum, Loss_function)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m  Val accuracy: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;132;01m%  Lo\u001b[39;00m\u001b[38;5;124mss: \u001b[39m\u001b[38;5;132;01m{:.6f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    112\u001b[0m     epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, acc_val \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, loss_val,\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(improved)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loss_val \u001b[38;5;241m<\u001b[39m best_loss_val \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m==\u001b[39mepochs:\n\u001b[1;32m--> 115\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43mEpoch: \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m  Val accuracy: \u001b[39;49m\u001b[38;5;132;43;01m{:.4f}\u001b[39;49;00m\u001b[38;5;132;43;01m%  Lo\u001b[39;49;00m\u001b[38;5;124;43mss: \u001b[39;49m\u001b[38;5;132;43;01m{:.6f}\u001b[39;49;00m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macc_val\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_val\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_val \u001b[38;5;241m<\u001b[39m best_loss_val:\n\u001b[0;32m    119\u001b[0m     best_loss_val \u001b[38;5;241m=\u001b[39m loss_val\n",
      "\u001b[1;31mIndexError\u001b[0m: Replacement index 3 out of range for positional args tuple"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    Training_config = config.get_training_config()\n",
    "    Training_step = Training(config=Training_config)\n",
    "    Training_step.loading_iterators()\n",
    "    Training_step.initializing_model()\n",
    "    Training_step.train()\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
